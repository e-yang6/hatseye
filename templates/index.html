<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HATSEYE - Webcam Display</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            width: 100%;
            height: 100vh;
            background-color: white;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
        }

        .container {
            position: relative;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            width: 100%;
            height: 100%;
        }

        .logo-container {
            position: fixed;
            top: 20px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 100;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #logo {
            max-width: 200px;
            max-height: 80px;
            width: auto;
            height: auto;
            object-fit: contain;
            display: block;
        }

        /* Hide logo container if logo fails to load */
        .logo-container:has(img[style*="display: none"]) {
            display: none;
        }

        #webcam-stream {
            max-width: 100%;
            max-height: 100vh;
            width: auto;
            height: auto;
            object-fit: contain;
        }

        /* All status and UI elements hidden */
        .status-bar,
        .response-box,
        .listening-indicator {
            display: none !important;
        }

        .error-message {
            display: none;
            color: #666;
            text-align: center;
            padding: 20px;
            font-size: 16px;
        }

        .error-message.show {
            display: block;
        }

        .loading {
            display: none;
            color: #999;
            text-align: center;
            font-size: 14px;
            margin-top: 20px;
        }

        .loading.show {
            display: block;
        }

        /* Invisible activation overlay - activates on any click */
        .activation-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: transparent;
            z-index: 10000;
            cursor: pointer;
        }

        .activation-overlay.hidden {
            display: none;
        }

        .activation-button,
        .activation-text,
        .activation-title {
            display: none;
        }
    </style>
</head>
<body>
    <!-- Invisible activation overlay - click anywhere to activate -->
    <div class="activation-overlay" id="activation-overlay" title="Click anywhere to activate"></div>
    
    <!-- Logo container - top center -->
    <div class="logo-container">
        <img id="logo" src="{{ url_for('static', filename='logo.png') }}" alt="HATSEYE Logo" onerror="this.style.display='none'; this.parentElement.style.display='none';">
    </div>

    <div class="container">
        <div>
            <img id="webcam-stream" src="{{ url_for('video_feed') }}" alt="Webcam Stream">
            <div class="error-message" id="error-message">
                Could not access webcam. Please check your camera permissions and make sure no other application is using it.
            </div>
            <div class="loading" id="loading">Loading webcam...</div>
        </div>
    </div>


    <script>
        const webcamStream = document.getElementById('webcam-stream');
        const errorMessage = document.getElementById('error-message');
        const loading = document.getElementById('loading');

        let recognition = null;
        let isListening = false;
        let wakeWordDetected = false;
        let audioContext = null;
        let audioEnabled = false;  // Track if user has interacted with page
        
        // Browser detection
        const isChrome = /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor);
        const isEdge = /Edg/.test(navigator.userAgent);
        const isSafari = /Safari/.test(navigator.userAgent) && /Apple Computer/.test(navigator.vendor);
        const isFirefox = /Firefox/.test(navigator.userAgent);

        // Wake word variations (reasonable matching)
        const wakePhrases = [
            // Original variations
            'hey hats eye', 'hey hats i', 'hey hat eye', 'hey hat i',
            'hats eye', 'hat eye', 'hats i', 'hat i',
            // Phonetic variations
            'hot sauce', 'hot saw', 'hat sauce', 'hat saw',
            'heart sauce', 'hard sauce', 'hot sighs', 'hat sighs',
            // Partial matches with context
            'hey hot', 'hey hat', 'hey heart', 'hey hard',
            // Common variations
            'hat seye', 'hats ai', 'hats aye', 'hats sauce',
            'hot eye', 'hot i', 'heart eye', 'hard eye'
        ];
        
        const wakeKeywords = {
            hats: ['hats', 'hat', 'hot', 'hut', 'hart', 'heart', 'hard'],
            eye: ['eye', 'i', 'ai', 'aye', 'sauce', 'saws', 'saw', 'so', 'sigh', 'sighs']
        };

        // Initialize Web Speech API
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = function() {
                    isListening = true;
                    console.log('Listening started');
                };

                recognition.onresult = function(event) {
                    const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
                    
                    // Check for wake word (EXTREMELY lenient)
                    if (!wakeWordDetected) {
                        let detected = false;
                        
                        // Check for exact phrase matches first
                        for (const phrase of wakePhrases) {
                            if (transcript.includes(phrase)) {
                                detected = true;
                                break;
                            }
                        }
                        
                        // If not detected, check for keyword combinations
                        if (!detected) {
                            const words = transcript.split(/\s+/);
                            
                            // Require at least 2 words
                            if (words.length < 2) {
                                return;
                            }
                            
                            // Check for keywords in actual words (not substrings)
                            const hasHat = words.some(word => wakeKeywords.hats.some(kw => word.toLowerCase().includes(kw)));
                            const hasEye = words.some(word => wakeKeywords.eye.some(kw => word.toLowerCase().includes(kw)));
                            
                            // Require BOTH keywords in 2-3 word phrase
                            if (words.length >= 2 && words.length <= 3 && hasHat && hasEye) {
                                detected = true;
                            }
                            
                            // Or if "hey"/"hi" + both keywords in 2-4 word phrase
                            const hasHey = transcript.includes('hey') || transcript.includes('hi');
                            if (!detected && hasHey && words.length <= 4 && hasHat && hasEye) {
                                detected = true;
                            }
                        }
                        
                        if (detected) {
                            wakeWordDetected = true;
                            console.log('Wake word detected:', transcript);
                            // Play wake word sound immediately
                            playSound('wake_word_sound.mp3');
                        }
                    } else {
                        // Question received
                        wakeWordDetected = false;
                        console.log('Question received:', transcript);
                        // Play question received sound immediately
                        playSound('question_received_sound.mp3');
                        
                        // Stop listening temporarily
                        recognition.stop();
                        
                        // Analyze image after a brief delay to let sound play
                        setTimeout(() => {
                            analyzeImage(transcript);
                        }, 300);
                    }
                };

                recognition.onerror = function(event) {
                    console.error('Speech recognition error:', event.error);
                    if (event.error === 'no-speech') {
                        // Restart if no speech detected
                        if (wakeWordDetected) {
                            wakeWordDetected = false;
                        }
                    }
                };

                recognition.onend = function() {
                    isListening = false;
                    console.log('Listening stopped');
                    
                    // Restart if we should be listening
                    if (!wakeWordDetected) {
                        setTimeout(() => {
                            if (recognition && !isListening) {
                                try {
                                    recognition.start();
                                } catch (e) {
                                    console.error('Failed to restart recognition:', e);
                                }
                            }
                        }, 100);
                    }
                };

                // Request microphone permission first
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(function(stream) {
                        // Microphone access granted, start recognition
                        stream.getTracks().forEach(track => track.stop()); // Stop the stream, we only needed permission
                        
                        try {
                            recognition.start();
                            console.log('Speech recognition started');
                        } catch (e) {
                            console.error('Failed to start recognition:', e);
                        }
                    })
                    .catch(function(err) {
                        console.error('Microphone access denied or unavailable:', err);
                        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                            console.warn('Microphone permission denied');
                        } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                            console.warn('No microphone found');
                        } else if (location.protocol !== 'https:' && location.hostname !== 'localhost' && location.hostname !== '127.0.0.1') {
                            console.warn('Requires HTTPS for microphone access');
                        } else {
                            console.error('Microphone error:', err.message);
                        }
                    });
            } else {
                console.warn('Web Speech API not available in this browser');
            }
        }

        // Analyze image with Gemini
        async function analyzeImage(question) {
            try {
                const response = await fetch('/analyze', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ question: question })
                });

                const data = await response.json();
                
                if (data.error) {
                    console.error('Analysis error:', data.error);
                    return;
                }

                const result = data.result;
                const isError = data.is_error;

                console.log('Analysis result:', result);

                // Play TTS if not an error
                if (!isError && result && !result.startsWith('Error:')) {
                    playTTS(result);
                }

                // Restart listening after a delay
                setTimeout(() => {
                    if (recognition && !isListening) {
                        try {
                            recognition.start();
                        } catch (e) {
                            console.error('Failed to restart recognition:', e);
                        }
                    }
                }, 2000);

            } catch (error) {
                console.error('Analysis error:', error);
                
                // Restart listening
                setTimeout(() => {
                    if (recognition && !isListening) {
                        try {
                            recognition.start();
                        } catch (e) {
                            console.error('Failed to restart recognition:', e);
                        }
                    }
                }, 2000);
            }
        }

        // Play TTS audio
        async function playTTS(text) {
            console.log('Requesting TTS for:', text);
            try {
                const response = await fetch('/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: text })
                });

                console.log('TTS response status:', response.status, response.statusText);

                if (response.ok) {
                    const audioBlob = await response.blob();
                    console.log('TTS audio blob received, size:', audioBlob.size, 'bytes');
                    
                    if (audioBlob.size === 0) {
                        console.error('TTS returned empty audio blob');
                        return;
                    }
                    
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    
                    audio.oncanplaythrough = function() {
                        console.log('TTS audio ready to play');
                    };
                    
                    audio.onended = () => {
                        console.log('TTS audio finished');
                        URL.revokeObjectURL(audioUrl);
                    };
                    
                    audio.onerror = (e) => {
                        console.error('TTS audio playback error:', e);
                        console.error('Audio error details:', audio.error);
                        URL.revokeObjectURL(audioUrl);
                    };
                    
                    try {
                        await audio.play();
                        console.log('TTS audio playing');
                    } catch (playError) {
                        console.error('Failed to play TTS audio:', playError);
                    }
                } else {
                    const errorData = await response.text();
                    console.error('TTS request failed:', response.status, errorData);
                }
            } catch (error) {
                console.error('TTS error:', error);
            }
        }

        // Enable audio - must be called after user interaction
        function enableAudio() {
            audioEnabled = true;
            console.log('Audio enabled - sounds can now play');
            
            // Preload and play a silent sound to unlock audio context
            const silentAudio = new Audio('data:audio/wav;base64,UklGRigAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQQAAAAAAA==');
            silentAudio.play().catch(e => {
                console.log('Silent audio unlock failed (this is ok):', e);
            });
        }

        // Play sound file from public folder
        function playSound(filename) {
            if (!audioEnabled) {
                console.warn('Audio not enabled yet - sound will not play:', filename);
                return;
            }
            
            console.log('Playing sound:', filename);
            const audio = new Audio('/sound/' + filename);
            
            // Preload
            audio.preload = 'auto';
            
            audio.oncanplaythrough = function() {
                console.log('Sound ready to play:', filename);
            };
            
            audio.onerror = function(e) {
                console.error('Sound play error:', filename, e);
                console.error('Audio error details:', audio.error);
            };
            
            audio.play()
                .then(() => {
                    console.log('Sound playing:', filename);
                })
                .catch(e => {
                    console.error('Sound play failed:', filename, e);
                    // Try again after a short delay
                    setTimeout(() => {
                        audio.play().catch(e2 => {
                            console.error('Retry failed:', filename, e2);
                        });
                    }, 100);
                });
        }

        // Check system status (silently, no UI)
        async function checkStatus() {
            try {
                const response = await fetch('/status');
                const data = await response.json();
                console.log('System status:', data);
            } catch (error) {
                console.error('Status check error:', error);
            }
        }

        // Handle image load
        webcamStream.onload = function() {
            loading.classList.remove('show');
            errorMessage.classList.remove('show');
        };

        // Handle image errors
        webcamStream.onerror = function() {
            loading.classList.remove('show');
            errorMessage.classList.add('show');
            
            setTimeout(function() {
                webcamStream.src = "{{ url_for('video_feed') }}?t=" + new Date().getTime();
            }, 2000);
        };

        // Force reload if image doesn't load within 3 seconds
        setTimeout(function() {
            if (loading.classList.contains('show')) {
                webcamStream.src = "{{ url_for('video_feed') }}?t=" + new Date().getTime();
            }
        }, 3000);

        // Handle activation overlay click (anywhere on page)
        const activationOverlay = document.getElementById('activation-overlay');
        activationOverlay.addEventListener('click', function() {
            console.log('Page clicked - activating audio and voice recognition');
            enableAudio();
            
            // Hide activation overlay
            activationOverlay.classList.add('hidden');
            
            // Initialize speech recognition after user interaction
            initSpeechRecognition();
            
            // Check status
            checkStatus();
            setInterval(checkStatus, 30000); // Check status every 30 seconds
        });

        // Initialize on page load (but don't start recognition until activation)
        window.addEventListener('load', function() {
            checkStatus();
            // Don't initialize speech recognition until user clicks activate button
            // This ensures we have user interaction for audio playback
        });
    </script>
</body>
</html>
